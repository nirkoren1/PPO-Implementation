{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1630b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from ppo_train import PPO\n",
    "from losses import Clip_Loss, No_clip_Loss, KL_Penalty_Loss\n",
    "from constants import seven_env_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e10199",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [\n",
    "    {\n",
    "        \"name\": \"No clipping or penalty\",\n",
    "        \"loss_class\": No_clip_Loss,\n",
    "        \"loss_kwargs\": {},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Clipping, ε = 0.1\",\n",
    "        \"loss_class\": Clip_Loss,\n",
    "        \"loss_kwargs\": {\"clip_coef\": 0.1},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Clipping, ε = 0.2\",\n",
    "        \"loss_class\": Clip_Loss,\n",
    "        \"loss_kwargs\": {\"clip_coef\": 0.2},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Clipping, ε = 0.3\",\n",
    "        \"loss_class\": Clip_Loss,\n",
    "        \"loss_kwargs\": {\"clip_coef\": 0.3},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Adaptive KL, dtarg = 0.003\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 1.0, \"adaptive_kl\": True, \"d_targ\": 0.003},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Adaptive KL, dtarg = 0.01\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 1.0, \"adaptive_kl\": True, \"d_targ\": 0.01},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Adaptive KL, dtarg = 0.03\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 1.0, \"adaptive_kl\": True, \"d_targ\": 0.03},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Fixed KL, β = 0.3\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 0.3},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Fixed KL, β = 1.0\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 1.0},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Fixed KL, β = 3.0\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 3.0},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Fixed KL, β = 10.0\",\n",
    "        \"loss_class\": KL_Penalty_Loss,\n",
    "        \"loss_kwargs\": {\"beta\": 10.0},\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01eab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = seven_env_names\n",
    "seeds = [1, 2, 3]\n",
    "TOTAL_TIMESTEPS = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3028eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd631408b01d4b5088c2b1b4ec7e4f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running: No clipping or penalty on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on Walker2d-v5 with seed 1. Final Reward: 22.59 ---\n",
      "--- Running: No clipping or penalty on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on Walker2d-v5 with seed 2. Final Reward: -31.17 ---\n",
      "--- Running: No clipping or penalty on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on Walker2d-v5 with seed 3. Final Reward: -105.83 ---\n",
      "--- Running: No clipping or penalty on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on HalfCheetah-v5 with seed 1. Final Reward: -1068947.80 ---\n",
      "--- Running: No clipping or penalty on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on HalfCheetah-v5 with seed 2. Final Reward: -5930.08 ---\n",
      "--- Running: No clipping or penalty on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on HalfCheetah-v5 with seed 3. Final Reward: -3702422.94 ---\n",
      "--- Running: No clipping or penalty on Hopper-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on Hopper-v5 with seed 1. Final Reward: 16.03 ---\n",
      "--- Running: No clipping or penalty on Hopper-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on Hopper-v5 with seed 2. Final Reward: -103.06 ---\n",
      "--- Running: No clipping or penalty on Hopper-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on Hopper-v5 with seed 3. Final Reward: 5.94 ---\n",
      "--- Running: No clipping or penalty on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on InvertedDoublePendulum-v5 with seed 1. Final Reward: 21.57 ---\n",
      "--- Running: No clipping or penalty on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on InvertedDoublePendulum-v5 with seed 2. Final Reward: 20.39 ---\n",
      "--- Running: No clipping or penalty on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on InvertedDoublePendulum-v5 with seed 3. Final Reward: 20.98 ---\n",
      "--- Running: No clipping or penalty on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on InvertedPendulum-v5 with seed 1. Final Reward: 2.00 ---\n",
      "--- Running: No clipping or penalty on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on InvertedPendulum-v5 with seed 2. Final Reward: 2.00 ---\n",
      "--- Running: No clipping or penalty on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on InvertedPendulum-v5 with seed 3. Final Reward: 2.00 ---\n",
      "--- Running: No clipping or penalty on Reacher-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on Reacher-v5 with seed 1. Final Reward: -10475.95 ---\n",
      "--- Running: No clipping or penalty on Reacher-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on Reacher-v5 with seed 2. Final Reward: -1184.85 ---\n",
      "--- Running: No clipping or penalty on Reacher-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on Reacher-v5 with seed 3. Final Reward: -191857.56 ---\n",
      "--- Running: No clipping or penalty on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: No clipping or penalty on Swimmer-v5 with seed 1. Final Reward: -0.31 ---\n",
      "--- Running: No clipping or penalty on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: No clipping or penalty on Swimmer-v5 with seed 2. Final Reward: -18.58 ---\n",
      "--- Running: No clipping or penalty on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: No clipping or penalty on Swimmer-v5 with seed 3. Final Reward: -22.18 ---\n",
      "--- Running: Clipping, ε = 0.1 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Walker2d-v5 with seed 1. Final Reward: 1049.70 ---\n",
      "--- Running: Clipping, ε = 0.1 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Walker2d-v5 with seed 2. Final Reward: 688.45 ---\n",
      "--- Running: Clipping, ε = 0.1 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Walker2d-v5 with seed 3. Final Reward: 932.76 ---\n",
      "--- Running: Clipping, ε = 0.1 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on HalfCheetah-v5 with seed 1. Final Reward: 1483.22 ---\n",
      "--- Running: Clipping, ε = 0.1 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on HalfCheetah-v5 with seed 2. Final Reward: 1224.99 ---\n",
      "--- Running: Clipping, ε = 0.1 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on HalfCheetah-v5 with seed 3. Final Reward: 1304.09 ---\n",
      "--- Running: Clipping, ε = 0.1 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Hopper-v5 with seed 1. Final Reward: 1726.44 ---\n",
      "--- Running: Clipping, ε = 0.1 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Hopper-v5 with seed 2. Final Reward: 1170.43 ---\n",
      "--- Running: Clipping, ε = 0.1 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Hopper-v5 with seed 3. Final Reward: 1632.90 ---\n",
      "--- Running: Clipping, ε = 0.1 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 5423.00 ---\n",
      "--- Running: Clipping, ε = 0.1 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 2452.37 ---\n",
      "--- Running: Clipping, ε = 0.1 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 5333.07 ---\n",
      "--- Running: Clipping, ε = 0.1 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on InvertedPendulum-v5 with seed 1. Final Reward: 632.93 ---\n",
      "--- Running: Clipping, ε = 0.1 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on InvertedPendulum-v5 with seed 2. Final Reward: 694.15 ---\n",
      "--- Running: Clipping, ε = 0.1 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on InvertedPendulum-v5 with seed 3. Final Reward: 601.62 ---\n",
      "--- Running: Clipping, ε = 0.1 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Reacher-v5 with seed 1. Final Reward: -6.39 ---\n",
      "--- Running: Clipping, ε = 0.1 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Reacher-v5 with seed 2. Final Reward: -8.55 ---\n",
      "--- Running: Clipping, ε = 0.1 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Reacher-v5 with seed 3. Final Reward: -6.41 ---\n",
      "--- Running: Clipping, ε = 0.1 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Swimmer-v5 with seed 1. Final Reward: 101.65 ---\n",
      "--- Running: Clipping, ε = 0.1 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Swimmer-v5 with seed 2. Final Reward: 106.11 ---\n",
      "--- Running: Clipping, ε = 0.1 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.1 on Swimmer-v5 with seed 3. Final Reward: 94.18 ---\n",
      "--- Running: Clipping, ε = 0.2 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Walker2d-v5 with seed 1. Final Reward: 725.93 ---\n",
      "--- Running: Clipping, ε = 0.2 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Walker2d-v5 with seed 2. Final Reward: 982.73 ---\n",
      "--- Running: Clipping, ε = 0.2 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Walker2d-v5 with seed 3. Final Reward: 652.40 ---\n",
      "--- Running: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 1. Final Reward: 1639.48 ---\n",
      "--- Running: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 2. Final Reward: -700.51 ---\n",
      "--- Running: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 3. Final Reward: 1097.78 ---\n",
      "--- Running: Clipping, ε = 0.2 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Hopper-v5 with seed 1. Final Reward: 1365.57 ---\n",
      "--- Running: Clipping, ε = 0.2 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Hopper-v5 with seed 2. Final Reward: 1068.23 ---\n",
      "--- Running: Clipping, ε = 0.2 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Hopper-v5 with seed 3. Final Reward: 1562.33 ---\n",
      "--- Running: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 4228.65 ---\n",
      "--- Running: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 3154.86 ---\n",
      "--- Running: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 5651.12 ---\n",
      "--- Running: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 1. Final Reward: 884.28 ---\n",
      "--- Running: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 2. Final Reward: 975.10 ---\n",
      "--- Running: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 3. Final Reward: 906.62 ---\n",
      "--- Running: Clipping, ε = 0.2 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Reacher-v5 with seed 1. Final Reward: -6.88 ---\n",
      "--- Running: Clipping, ε = 0.2 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Reacher-v5 with seed 2. Final Reward: -7.71 ---\n",
      "--- Running: Clipping, ε = 0.2 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Reacher-v5 with seed 3. Final Reward: -5.70 ---\n",
      "--- Running: Clipping, ε = 0.2 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Swimmer-v5 with seed 1. Final Reward: 84.40 ---\n",
      "--- Running: Clipping, ε = 0.2 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Swimmer-v5 with seed 2. Final Reward: 84.21 ---\n",
      "--- Running: Clipping, ε = 0.2 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.2 on Swimmer-v5 with seed 3. Final Reward: 72.86 ---\n",
      "--- Running: Clipping, ε = 0.3 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Walker2d-v5 with seed 1. Final Reward: 1165.13 ---\n",
      "--- Running: Clipping, ε = 0.3 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Walker2d-v5 with seed 2. Final Reward: 872.85 ---\n",
      "--- Running: Clipping, ε = 0.3 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Walker2d-v5 with seed 3. Final Reward: 1651.53 ---\n",
      "--- Running: Clipping, ε = 0.3 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on HalfCheetah-v5 with seed 1. Final Reward: 851.95 ---\n",
      "--- Running: Clipping, ε = 0.3 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on HalfCheetah-v5 with seed 2. Final Reward: 1894.22 ---\n",
      "--- Running: Clipping, ε = 0.3 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on HalfCheetah-v5 with seed 3. Final Reward: 2649.54 ---\n",
      "--- Running: Clipping, ε = 0.3 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Hopper-v5 with seed 1. Final Reward: 754.69 ---\n",
      "--- Running: Clipping, ε = 0.3 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Hopper-v5 with seed 2. Final Reward: 998.10 ---\n",
      "--- Running: Clipping, ε = 0.3 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Hopper-v5 with seed 3. Final Reward: 959.84 ---\n",
      "--- Running: Clipping, ε = 0.3 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 142.54 ---\n",
      "--- Running: Clipping, ε = 0.3 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 296.47 ---\n",
      "--- Running: Clipping, ε = 0.3 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 320.86 ---\n",
      "--- Running: Clipping, ε = 0.3 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on InvertedPendulum-v5 with seed 1. Final Reward: 725.18 ---\n",
      "--- Running: Clipping, ε = 0.3 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on InvertedPendulum-v5 with seed 2. Final Reward: 867.61 ---\n",
      "--- Running: Clipping, ε = 0.3 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on InvertedPendulum-v5 with seed 3. Final Reward: 793.44 ---\n",
      "--- Running: Clipping, ε = 0.3 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Reacher-v5 with seed 1. Final Reward: -9.55 ---\n",
      "--- Running: Clipping, ε = 0.3 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Reacher-v5 with seed 2. Final Reward: -8.76 ---\n",
      "--- Running: Clipping, ε = 0.3 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Reacher-v5 with seed 3. Final Reward: -18.74 ---\n",
      "--- Running: Clipping, ε = 0.3 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Swimmer-v5 with seed 1. Final Reward: 53.34 ---\n",
      "--- Running: Clipping, ε = 0.3 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Swimmer-v5 with seed 2. Final Reward: 46.45 ---\n",
      "--- Running: Clipping, ε = 0.3 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Clipping, ε = 0.3 on Swimmer-v5 with seed 3. Final Reward: 67.93 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Walker2d-v5 with seed 1. Final Reward: 280.98 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Walker2d-v5 with seed 2. Final Reward: 350.00 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Walker2d-v5 with seed 3. Final Reward: 353.35 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on HalfCheetah-v5 with seed 1. Final Reward: -34151.39 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on HalfCheetah-v5 with seed 2. Final Reward: -33921.38 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on HalfCheetah-v5 with seed 3. Final Reward: -34802.40 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Hopper-v5 with seed 1. Final Reward: 1190.11 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Hopper-v5 with seed 2. Final Reward: 953.73 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Hopper-v5 with seed 3. Final Reward: 1677.96 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 6509.85 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 5769.05 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 6208.49 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on InvertedPendulum-v5 with seed 1. Final Reward: 794.97 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on InvertedPendulum-v5 with seed 2. Final Reward: 915.55 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on InvertedPendulum-v5 with seed 3. Final Reward: 930.89 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Reacher-v5 with seed 1. Final Reward: -11.50 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Reacher-v5 with seed 2. Final Reward: -8579246.99 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Reacher-v5 with seed 3. Final Reward: -10.27 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Swimmer-v5 with seed 1. Final Reward: 88.67 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Swimmer-v5 with seed 2. Final Reward: 94.39 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.003 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.003 on Swimmer-v5 with seed 3. Final Reward: 97.43 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Walker2d-v5 with seed 1. Final Reward: 345.46 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Walker2d-v5 with seed 2. Final Reward: 413.01 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Walker2d-v5 with seed 3. Final Reward: 295.45 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on HalfCheetah-v5 with seed 1. Final Reward: -29633.08 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on HalfCheetah-v5 with seed 2. Final Reward: -31542.99 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on HalfCheetah-v5 with seed 3. Final Reward: -30772.56 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Hopper-v5 with seed 1. Final Reward: 1576.24 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Hopper-v5 with seed 2. Final Reward: 1135.69 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Hopper-v5 with seed 3. Final Reward: 991.94 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 5152.59 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 5710.21 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 5514.41 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on InvertedPendulum-v5 with seed 1. Final Reward: 858.65 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on InvertedPendulum-v5 with seed 2. Final Reward: 806.74 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on InvertedPendulum-v5 with seed 3. Final Reward: 1000.00 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Reacher-v5 with seed 1. Final Reward: -7.18 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Reacher-v5 with seed 2. Final Reward: -15.08 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Reacher-v5 with seed 3. Final Reward: -10.35 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Swimmer-v5 with seed 1. Final Reward: 93.65 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Swimmer-v5 with seed 2. Final Reward: 85.94 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.01 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.01 on Swimmer-v5 with seed 3. Final Reward: 84.90 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Walker2d-v5 with seed 1. Final Reward: 273.94 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Walker2d-v5 with seed 2. Final Reward: 251.06 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Walker2d-v5 with seed 3. Final Reward: 351.15 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on HalfCheetah-v5 with seed 1. Final Reward: -12521.75 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on HalfCheetah-v5 with seed 2. Final Reward: -21993.49 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on HalfCheetah-v5 with seed 3. Final Reward: -24858.55 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Hopper-v5 with seed 1. Final Reward: 971.56 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Hopper-v5 with seed 2. Final Reward: 1019.42 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Hopper-v5 with seed 3. Final Reward: 1134.92 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 4264.07 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 3783.32 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 4178.13 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on InvertedPendulum-v5 with seed 1. Final Reward: 996.04 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on InvertedPendulum-v5 with seed 2. Final Reward: 958.65 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on InvertedPendulum-v5 with seed 3. Final Reward: 953.64 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Reacher-v5 with seed 1. Final Reward: -9.98 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Reacher-v5 with seed 2. Final Reward: -5.48 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Reacher-v5 with seed 3. Final Reward: -9.20 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Swimmer-v5 with seed 1. Final Reward: 82.25 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Swimmer-v5 with seed 2. Final Reward: 85.77 ---\n",
      "--- Running: Adaptive KL, dtarg = 0.03 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Adaptive KL, dtarg = 0.03 on Swimmer-v5 with seed 3. Final Reward: 80.99 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Walker2d-v5 with seed 1. Final Reward: 591.06 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Walker2d-v5 with seed 2. Final Reward: 256.01 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Walker2d-v5 with seed 3. Final Reward: 66.07 ---\n",
      "--- Running: Fixed KL, β = 0.3 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on HalfCheetah-v5 with seed 1. Final Reward: -153868.89 ---\n",
      "--- Running: Fixed KL, β = 0.3 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on HalfCheetah-v5 with seed 2. Final Reward: -365883.64 ---\n",
      "--- Running: Fixed KL, β = 0.3 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on HalfCheetah-v5 with seed 3. Final Reward: -165438.19 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Hopper-v5 with seed 1. Final Reward: 297.08 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Hopper-v5 with seed 2. Final Reward: 368.52 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Hopper-v5 with seed 3. Final Reward: 177.81 ---\n",
      "--- Running: Fixed KL, β = 0.3 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 148.76 ---\n",
      "--- Running: Fixed KL, β = 0.3 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 150.38 ---\n",
      "--- Running: Fixed KL, β = 0.3 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 145.06 ---\n",
      "--- Running: Fixed KL, β = 0.3 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on InvertedPendulum-v5 with seed 1. Final Reward: 934.61 ---\n",
      "--- Running: Fixed KL, β = 0.3 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on InvertedPendulum-v5 with seed 2. Final Reward: 1000.00 ---\n",
      "--- Running: Fixed KL, β = 0.3 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on InvertedPendulum-v5 with seed 3. Final Reward: 693.62 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Reacher-v5 with seed 1. Final Reward: -13929739.83 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Reacher-v5 with seed 2. Final Reward: -1611874.38 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Reacher-v5 with seed 3. Final Reward: -3560378.51 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Swimmer-v5 with seed 1. Final Reward: 70.73 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Swimmer-v5 with seed 2. Final Reward: 76.95 ---\n",
      "--- Running: Fixed KL, β = 0.3 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 0.3 on Swimmer-v5 with seed 3. Final Reward: 76.74 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Walker2d-v5 with seed 1. Final Reward: 901.69 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Walker2d-v5 with seed 2. Final Reward: 621.67 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Walker2d-v5 with seed 3. Final Reward: 458.20 ---\n",
      "--- Running: Fixed KL, β = 1.0 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on HalfCheetah-v5 with seed 1. Final Reward: -2624.16 ---\n",
      "--- Running: Fixed KL, β = 1.0 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on HalfCheetah-v5 with seed 2. Final Reward: -489832.18 ---\n",
      "--- Running: Fixed KL, β = 1.0 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on HalfCheetah-v5 with seed 3. Final Reward: -1499.82 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Hopper-v5 with seed 1. Final Reward: 722.25 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Hopper-v5 with seed 2. Final Reward: 418.71 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Hopper-v5 with seed 3. Final Reward: 676.25 ---\n",
      "--- Running: Fixed KL, β = 1.0 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 160.88 ---\n",
      "--- Running: Fixed KL, β = 1.0 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 190.76 ---\n",
      "--- Running: Fixed KL, β = 1.0 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 210.68 ---\n",
      "--- Running: Fixed KL, β = 1.0 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on InvertedPendulum-v5 with seed 1. Final Reward: 901.77 ---\n",
      "--- Running: Fixed KL, β = 1.0 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on InvertedPendulum-v5 with seed 2. Final Reward: 995.11 ---\n",
      "--- Running: Fixed KL, β = 1.0 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on InvertedPendulum-v5 with seed 3. Final Reward: 961.61 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Reacher-v5 with seed 1. Final Reward: -34468895.27 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Reacher-v5 with seed 2. Final Reward: -7.03 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Reacher-v5 with seed 3. Final Reward: -770.47 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Swimmer-v5 with seed 1. Final Reward: 95.54 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Swimmer-v5 with seed 2. Final Reward: 95.89 ---\n",
      "--- Running: Fixed KL, β = 1.0 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 1.0 on Swimmer-v5 with seed 3. Final Reward: 52.60 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Walker2d-v5 with seed 1. Final Reward: 332.62 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Walker2d-v5 with seed 2. Final Reward: 675.29 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Walker2d-v5 with seed 3. Final Reward: 260.23 ---\n",
      "--- Running: Fixed KL, β = 3.0 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on HalfCheetah-v5 with seed 1. Final Reward: -17698.31 ---\n",
      "--- Running: Fixed KL, β = 3.0 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on HalfCheetah-v5 with seed 2. Final Reward: -4024.83 ---\n",
      "--- Running: Fixed KL, β = 3.0 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on HalfCheetah-v5 with seed 3. Final Reward: -1117.76 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Hopper-v5 with seed 1. Final Reward: 771.46 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Hopper-v5 with seed 2. Final Reward: 880.13 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Hopper-v5 with seed 3. Final Reward: 1147.58 ---\n",
      "--- Running: Fixed KL, β = 3.0 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 345.41 ---\n",
      "--- Running: Fixed KL, β = 3.0 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 361.01 ---\n",
      "--- Running: Fixed KL, β = 3.0 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 153.99 ---\n",
      "--- Running: Fixed KL, β = 3.0 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on InvertedPendulum-v5 with seed 1. Final Reward: 902.14 ---\n",
      "--- Running: Fixed KL, β = 3.0 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on InvertedPendulum-v5 with seed 2. Final Reward: 986.80 ---\n",
      "--- Running: Fixed KL, β = 3.0 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on InvertedPendulum-v5 with seed 3. Final Reward: 978.27 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Reacher-v5 with seed 1. Final Reward: -9.21 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Reacher-v5 with seed 2. Final Reward: -6.40 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Reacher-v5 with seed 3. Final Reward: -9.73 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Swimmer-v5 with seed 1. Final Reward: 92.66 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Swimmer-v5 with seed 2. Final Reward: 94.35 ---\n",
      "--- Running: Fixed KL, β = 3.0 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 3.0 on Swimmer-v5 with seed 3. Final Reward: 99.67 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Walker2d-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Walker2d-v5 with seed 1. Final Reward: 420.50 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Walker2d-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Walker2d-v5 with seed 2. Final Reward: 255.31 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Walker2d-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Walker2d-v5 with seed 3. Final Reward: 268.55 ---\n",
      "--- Running: Fixed KL, β = 10.0 on HalfCheetah-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on HalfCheetah-v5 with seed 1. Final Reward: 856.48 ---\n",
      "--- Running: Fixed KL, β = 10.0 on HalfCheetah-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on HalfCheetah-v5 with seed 2. Final Reward: 2418.51 ---\n",
      "--- Running: Fixed KL, β = 10.0 on HalfCheetah-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on HalfCheetah-v5 with seed 3. Final Reward: 949.45 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Hopper-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Hopper-v5 with seed 1. Final Reward: 792.93 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Hopper-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Hopper-v5 with seed 2. Final Reward: 1049.16 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Hopper-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Hopper-v5 with seed 3. Final Reward: 1057.72 ---\n",
      "--- Running: Fixed KL, β = 10.0 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 325.51 ---\n",
      "--- Running: Fixed KL, β = 10.0 on InvertedDoublePendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on InvertedDoublePendulum-v5 with seed 2. Final Reward: 273.23 ---\n",
      "--- Running: Fixed KL, β = 10.0 on InvertedDoublePendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on InvertedDoublePendulum-v5 with seed 3. Final Reward: 169.65 ---\n",
      "--- Running: Fixed KL, β = 10.0 on InvertedPendulum-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on InvertedPendulum-v5 with seed 1. Final Reward: 511.05 ---\n",
      "--- Running: Fixed KL, β = 10.0 on InvertedPendulum-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on InvertedPendulum-v5 with seed 2. Final Reward: 611.81 ---\n",
      "--- Running: Fixed KL, β = 10.0 on InvertedPendulum-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on InvertedPendulum-v5 with seed 3. Final Reward: 504.57 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Reacher-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Reacher-v5 with seed 1. Final Reward: -12.05 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Reacher-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Reacher-v5 with seed 2. Final Reward: -10.13 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Reacher-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Reacher-v5 with seed 3. Final Reward: -10.56 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Swimmer-v5 with seed 1 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Swimmer-v5 with seed 1. Final Reward: 71.61 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Swimmer-v5 with seed 2 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Swimmer-v5 with seed 2. Final Reward: 72.97 ---\n",
      "--- Running: Fixed KL, β = 10.0 on Swimmer-v5 with seed 3 ---\n",
      "--- Finished: Fixed KL, β = 10.0 on Swimmer-v5 with seed 3. Final Reward: 65.64 ---\n",
      "\n",
      "All experiments complete. Raw results saved to ppo_raw_results.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "total_runs = len(experiment_configs) * len(environments) * len(seeds)\n",
    "pbar = tqdm(total=total_runs, desc=\"Overall Progress\")\n",
    "\n",
    "for config in experiment_configs:\n",
    "    for env_name in environments:\n",
    "        for seed in seeds:\n",
    "            print(f\"--- Running: {config['name']} on {env_name} with seed {seed} ---\")\n",
    "            \n",
    "            try:\n",
    "                agent = PPO(\n",
    "                    env_name=env_name,\n",
    "                    num_envs=1,\n",
    "                    seed=seed,\n",
    "                    total_timesteps=TOTAL_TIMESTEPS,\n",
    "                    loss_fn_class=config['loss_class'],\n",
    "                    loss_kwargs=config['loss_kwargs'],\n",
    "                    verbose=False\n",
    "                )\n",
    "                final_reward = agent.train()\n",
    "                \n",
    "                result = {\n",
    "                    \"algorithm\": config['name'],\n",
    "                    \"environment\": env_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"final_reward\": final_reward\n",
    "                }\n",
    "                all_results.append(result)\n",
    "                \n",
    "                print(f\"Finished: {config['name']} on {env_name} with seed {seed}. Final Reward: {final_reward:.2f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {config['name']} on {env_name} with seed {seed}. Error: {e} !!!\")\n",
    "                result = {\n",
    "                    \"algorithm\": config['name'],\n",
    "                    \"environment\": env_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"final_reward\": -np.inf\n",
    "                }\n",
    "                all_results.append(result)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\"ppo_raw_results.csv\", index=False)\n",
    "print(\"\\nAll experiments complete. Raw results saved to ppo_raw_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081b3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d5ff777a744dc08b3a1b2ffe381aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Random Scores:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random score for Walker2d-v5: 1.30\n",
      "Random score for HalfCheetah-v5: -277.97\n",
      "Random score for Hopper-v5: 19.20\n",
      "Random score for InvertedDoublePendulum-v5: 47.46\n",
      "Random score for InvertedPendulum-v5: 4.51\n",
      "Random score for Reacher-v5: -42.82\n",
      "Random score for Swimmer-v5: 0.02\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "def get_random_policy_score(env_name, num_episodes=100):\n",
    "    env = gym.make(env_name)\n",
    "    total_rewards = []\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        obs, _ = env.reset(seed=i)\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "        total_rewards.append(episode_reward)\n",
    "        \n",
    "    env.close()\n",
    "    return np.mean(total_rewards)\n",
    "\n",
    "random_scores = {}\n",
    "for env_name in tqdm(environments, desc=\"Calculating Random Scores\"):\n",
    "    score = get_random_policy_score(env_name)\n",
    "    random_scores[env_name] = score\n",
    "    print(f\"Random score for {env_name}: {score:.2f}\")\n",
    "\n",
    "random_scores_df = pd.DataFrame(list(random_scores.items()), columns=['environment', 'random_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_df = results_df.groupby('environment')['final_reward'].max().reset_index()\n",
    "worst_scores_df = results_df.groupby('environment')['final_reward'].min().reset_index()\n",
    "best_scores_df.rename(columns={'final_reward': 'best_score'}, inplace=True)\n",
    "worst_scores_df.rename(columns={'final_reward': 'worst_score'}, inplace=True)\n",
    "\n",
    "env_scores = pd.merge(best_scores_df, random_scores_df, on='environment')\n",
    "env_scores = pd.merge(env_scores, worst_scores_df, on='environment')\n",
    "\n",
    "normalized_df = pd.merge(results_df, env_scores, on='environment')\n",
    "\n",
    "normalized_df['normalized_score'] = np.where(\n",
    "    (normalized_df['best_score'] - normalized_df['random_score']) == 0,\n",
    "    0,\n",
    "    (normalized_df['final_reward'] - normalized_df['random_score']) / (normalized_df['best_score'] - normalized_df['random_score'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46662cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: Results from continuous control benchmark.\n",
      "Average normalized scores (over 21 runs of the algorithm, on 7 environments) for each algorithm / hyperparameter setting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>avg. normalized score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No clipping or penalty</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clipping, ε = 0.1</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clipping, ε = 0.2</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clipping, ε = 0.3</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adaptive KL, dtarg = 0.003</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adaptive KL, dtarg = 0.01</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adaptive KL, dtarg = 0.03</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fixed KL, β = 0.3</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fixed KL, β = 1.0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fixed KL, β = 3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fixed KL, β = 10.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     algorithm  avg. normalized score\n",
       "10      No clipping or penalty                  -0.02\n",
       "3            Clipping, ε = 0.1                   0.69\n",
       "4            Clipping, ε = 0.2                   0.79\n",
       "5            Clipping, ε = 0.3                   0.64\n",
       "0   Adaptive KL, dtarg = 0.003                   0.84\n",
       "1    Adaptive KL, dtarg = 0.01                   0.80\n",
       "2    Adaptive KL, dtarg = 0.03                   0.65\n",
       "6            Fixed KL, β = 0.3                   0.09\n",
       "7            Fixed KL, β = 1.0                   0.38\n",
       "9            Fixed KL, β = 3.0                   0.50\n",
       "8           Fixed KL, β = 10.0                   0.51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_table = normalized_df.groupby('algorithm')['normalized_score'].median().reset_index()\n",
    "final_table.rename(columns={'normalized_score': 'avg. normalized score'}, inplace=True)\n",
    "\n",
    "algorithm_order = [config['name'] for config in experiment_configs]\n",
    "final_table['algorithm'] = pd.Categorical(final_table['algorithm'], categories=algorithm_order, ordered=True)\n",
    "final_table = final_table.sort_values('algorithm')\n",
    "\n",
    "\n",
    "print(\"Table 1: Results from continuous control benchmark.\")\n",
    "print(\"Average normalized scores (over 21 runs of the algorithm, on 7 environments) for each algorithm / hyperparameter setting.\")\n",
    "display(final_table.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 environment  final_reward\n",
      "0             HalfCheetah-v5   1639.476342\n",
      "1                  Hopper-v5   1562.328899\n",
      "2  InvertedDoublePendulum-v5   5651.123639\n",
      "3        InvertedPendulum-v5    975.100000\n",
      "4                 Reacher-v5     -5.696826\n",
      "5                 Swimmer-v5     84.402427\n",
      "6                Walker2d-v5    982.731343\n"
     ]
    }
   ],
   "source": [
    "cliping_results = pd.DataFrame()\n",
    "cliping_results = normalized_df[normalized_df['algorithm'] == 'Clipping, ε = 0.2'].groupby('environment')['final_reward'].max().reset_index()\n",
    "print(cliping_results.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9a0ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44739557ccec40b8ac5aa5f2bb3c424d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running: Clipping, ε = 0.2 on Walker2d-v5 with seed 1 ---\n",
      "Target score reached: 3003.423880224996\n",
      "Finished: Clipping, ε = 0.2 on Walker2d-v5 with seed 1. Final Reward: 3003.42 steps: 4239360\n",
      "--- Running: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 1 ---\n",
      "Target score reached: 2036.5806756811214\n",
      "Finished: Clipping, ε = 0.2 on HalfCheetah-v5 with seed 1. Final Reward: 2036.58 steps: 4136960\n",
      "--- Running: Clipping, ε = 0.2 on Hopper-v5 with seed 1 ---\n",
      "Target score reached: 2386.4269804049277\n",
      "Finished: Clipping, ε = 0.2 on Hopper-v5 with seed 1. Final Reward: 2386.43 steps: 1331200\n",
      "--- Running: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 1 ---\n",
      "Target score reached: 8792.76895001977\n",
      "Finished: Clipping, ε = 0.2 on InvertedDoublePendulum-v5 with seed 1. Final Reward: 8792.77 steps: 368640\n",
      "--- Running: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 1 ---\n",
      "Failed: Clipping, ε = 0.2 on InvertedPendulum-v5 with seed 1. Error: not enough values to unpack (expected 3, got 2)\n",
      "--- Running: Clipping, ε = 0.2 on Reacher-v5 with seed 1 ---\n",
      "Failed: Clipping, ε = 0.2 on Reacher-v5 with seed 1. Error: not enough values to unpack (expected 3, got 2)\n",
      "--- Running: Clipping, ε = 0.2 on Swimmer-v5 with seed 1 ---\n",
      "Target score reached: 110.83606158327945\n",
      "Finished: Clipping, ε = 0.2 on Swimmer-v5 with seed 1. Final Reward: 110.84 steps: 9768960\n",
      "\n",
      "All experiments complete. Raw results saved to ppo_raw_results_v2.csv\n"
     ]
    }
   ],
   "source": [
    "all_results_v2 = []\n",
    "\n",
    "experiment_configs = [\n",
    "    {\n",
    "        \"name\": \"Clipping, ε = 0.2\",\n",
    "        \"loss_class\": Clip_Loss,\n",
    "        \"loss_kwargs\": {\"clip_coef\": 0.2},\n",
    "    }\n",
    "]\n",
    "\n",
    "environments = seven_env_names\n",
    "seeds = [1]\n",
    "TOTAL_TIMESTEPS = 10_000_000\n",
    "\n",
    "original_results = {'Walker2d-v5': 3000,\n",
    "                   'HalfCheetah-v5': 2000,\n",
    "                   'Hopper-v5': 2300,\n",
    "                   'InvertedDoublePendulum-v5': 8000,\n",
    "                   'InvertedPendulum-v5': 1000,\n",
    "                   'Reacher-v5': -10,\n",
    "                   'Swimmer-v5': 110}\n",
    "\n",
    "total_runs = len(experiment_configs) * len(environments) * len(seeds)\n",
    "pbar = tqdm(total=total_runs, desc=\"Overall Progress\")\n",
    "\n",
    "for config in experiment_configs:\n",
    "    for env_name in environments:\n",
    "        for seed in seeds:\n",
    "            print(f\"--- Running: {config['name']} on {env_name} with seed {seed} ---\")\n",
    "            \n",
    "            try:\n",
    "                agent = PPO(\n",
    "                    env_name=env_name,\n",
    "                    num_envs=10,\n",
    "                    seed=seed,\n",
    "                    total_timesteps=TOTAL_TIMESTEPS,\n",
    "                    loss_fn_class=config['loss_class'],\n",
    "                    loss_kwargs=config['loss_kwargs'],\n",
    "                    verbose=False\n",
    "                )\n",
    "                final_reward, _, steps_taken = agent.train(target_score=original_results[env_name])\n",
    "                \n",
    "                result = {\n",
    "                    \"algorithm\": config['name'],\n",
    "                    \"environment\": env_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"final_reward\": final_reward,\n",
    "                    \"steps_taken\": steps_taken\n",
    "                }\n",
    "                all_results_v2.append(result)\n",
    "                \n",
    "                print(f\"Finished: {config['name']} on {env_name} with seed {seed}. Final Reward: {final_reward:.2f} steps: {steps_taken}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {config['name']} on {env_name} with seed {seed}. Error: {e}\")\n",
    "                result = {\n",
    "                    \"algorithm\": config['name'],\n",
    "                    \"environment\": env_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"final_reward\": -np.inf,\n",
    "                    \"steps_taken\": -np.inf\n",
    "                }\n",
    "                all_results_v2.append(result)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "results_df = pd.DataFrame(all_results_v2)\n",
    "results_df.to_csv(\"ppo_raw_results_v2.csv\", index=False)\n",
    "print(\"\\nAll experiments complete. Raw results saved to ppo_raw_results_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7552a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           algorithm                environment  seed  final_reward  \\\n",
      "0  Clipping, ε = 0.2                Walker2d-v5     1   3024.946599   \n",
      "1  Clipping, ε = 0.2             HalfCheetah-v5     1          -inf   \n",
      "2  Clipping, ε = 0.2                  Hopper-v5     1   2305.800322   \n",
      "3  Clipping, ε = 0.2  InvertedDoublePendulum-v5     1          -inf   \n",
      "4  Clipping, ε = 0.2        InvertedPendulum-v5     1          -inf   \n",
      "5  Clipping, ε = 0.2                 Reacher-v5     1     -9.698386   \n",
      "6  Clipping, ε = 0.2                 Swimmer-v5     1    110.079151   \n",
      "\n",
      "   steps_taken  \n",
      "0    7297024.0  \n",
      "1         -inf  \n",
      "2    2060288.0  \n",
      "3         -inf  \n",
      "4         -inf  \n",
      "5     122880.0  \n",
      "6    3293184.0  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c70df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3623493dffe44a90baf22840cb99ea28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running: Clipping, ε = 0.2 on Walker2d-v5 with seed 1 ---\n"
     ]
    }
   ],
   "source": [
    "all_results_v2 = []\n",
    "\n",
    "experiment_configs = [\n",
    "    {\n",
    "        \"name\": \"Clipping, ε = 0.2\",\n",
    "        \"loss_class\": Clip_Loss,\n",
    "        \"loss_kwargs\": {\"clip_coef\": 0.2},\n",
    "    }\n",
    "]\n",
    "\n",
    "environments = seven_env_names\n",
    "seeds = [1]\n",
    "TOTAL_TIMESTEPS = 5_000_000\n",
    "\n",
    "original_results = {'Walker2d-v5': 3000,\n",
    "                   'HalfCheetah-v5': 2000,\n",
    "                   'Hopper-v5': 2300,\n",
    "                   'InvertedDoublePendulum-v5': 8000,\n",
    "                   'InvertedPendulum-v5': 1000,\n",
    "                   'Reacher-v5': -10,\n",
    "                   'Swimmer-v5': 110}\n",
    "\n",
    "total_runs = len(experiment_configs) * len(environments) * len(seeds)\n",
    "pbar = tqdm(total=total_runs, desc=\"Overall Progress\")\n",
    "\n",
    "for config in experiment_configs:\n",
    "    for env_name in environments:\n",
    "        for seed in seeds:\n",
    "            print(f\"--- Running: {config['name']} on {env_name} with seed {seed} ---\")\n",
    "            \n",
    "            try:\n",
    "                agent = PPO(\n",
    "                    env_name=env_name,\n",
    "                    num_envs=12,\n",
    "                    seed=seed,\n",
    "                    total_timesteps=TOTAL_TIMESTEPS,\n",
    "                    loss_fn_class=config['loss_class'],\n",
    "                    loss_kwargs=config['loss_kwargs'],\n",
    "                    verbose=False\n",
    "                )\n",
    "                final_reward, _, steps_taken, one_million_reward = agent.train(original_results[env_name])\n",
    "                \n",
    "                result = {\n",
    "                    \"algorithm\": config['name'],\n",
    "                    \"environment\": env_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"final_reward\": final_reward,\n",
    "                    \"steps_taken\": steps_taken,\n",
    "                    \"one_million_reward\": one_million_reward\n",
    "                }\n",
    "                all_results_v2.append(result)\n",
    "                \n",
    "                print(f\"Finished: {config['name']} on {env_name} with seed {seed}. Final Reward: {final_reward:.2f}, one million reward: {one_million_reward:.2f}, steps: {steps_taken}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {config['name']} on {env_name} with seed {seed}. Error: {e}\")\n",
    "                result = {\n",
    "                    \"algorithm\": config['name'],\n",
    "                    \"environment\": env_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"final_reward\": -np.inf,\n",
    "                    \"steps_taken\": -np.inf,\n",
    "                    \"one_million_reward\": -np.inf\n",
    "                }\n",
    "                all_results_v2.append(result)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "results_df_1M = pd.DataFrame(all_results_v2)\n",
    "results_df_1M.to_csv(\"ppo_raw_results_v2_1M.csv\", index=False)\n",
    "print(\"\\nAll experiments complete. Raw results saved to ppo_raw_results_v2_1M.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
